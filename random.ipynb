{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the nifti file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "# Base directory\n",
    "base_directory = 'E:/project2/ADNI_IP'\n",
    "\n",
    "# List to store NIfTI images\n",
    "nifti_images = []\n",
    "\n",
    "# Recursive directory traversal\n",
    "for root, dirs, files in os.walk(base_directory):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith('.nii') or file_name.endswith('.nii.gz'):\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            nifti_img = nib.load(file_path)\n",
    "            nifti_images.append(nifti_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifti_images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorizing the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCI: I129313, I138792, I86030, I92444, I109196, I119158, I66824, I79784, I87493, I91703, I31500, I106524, I35653, I119733, I120544, I71302, I82223, I138844, I86318, I90866, I103654, I34168, I111192, I52107, I119204, I120446, I124536, I138011, I83512, I142375, I101432, I31623, I132215, I119006, I120256, I66009, I140734, I86345, I94863, I103681, I118668, I52138, I64800, I120460, I132918, I138103, I83549, I143116, I101566, I32777, I39197, I119026, I72405, I31392, I105848, I118916, I65268, I70611, I124008, I75459, I81981, I143554, I89124, I102675, I32817, I109187, I118856, I119146, I63508, I120618, I76601, I82686, I87106, I31468, I118790, I40404, I118922, I120521, I70687, I124115, I86231, I143856, I33114, I118871, I119201, I64077, I67174, I73073, I136193, I99265, I40692, I119001, I119735, I120553, I82509, I86327, I174851, I90916, I103663, I34866, I40254, I118882, I120451, I120798, I81434, I88270, I118851, I40840, I119018, I66018, I133882, I82556, I118908, I119721, I78663, I138580, I83554, I89123, I102204, I32785, I108422, I47757, I119032, I120423, I120606, I72427, I135570, I91168, I96239, I31446, I35029, I40392, I75471\n",
      "CN: I82102, I89933, I102840, I33046, I39288, I118858, I63565, I120746, I136188, I118837, I40657, I65874, I124170, I132451, I149636, I94476, I40191, I64116, I67380, I120789, I73347, I87739, I91921, I38878, I118848, I120562, I132800, I82551, I139891, I30968, I40269, I118904, I119712, I69136, I81874, I88372, I92316, I107779, I118852, I45126, I59986, I120416, I66740, I120580, I82571, I140782, I87046, I90989, I96052, I118679, I53836, I119725, I129286, I138627, I39203, I120426, I72864, I141230, I91173, I96312, I58054, I65561, I82205, I138806, I90026, I40172, I51934, I120779, I83389, I142107, I91912, I106542, I37190, I118846, I59214, I65952, I71312, I139325, I94563, I105888, I34190, I52129, I119685, I64551, I67781, I74496, I125029, I138050, I142425, I32755, I132220, I59955, I120403, I72352, I140739, I90942, I96034, I31107, I104471, I34371, I118675, I53802, I123767, I81937, I92363, I118854, I63475, I140800, I87064, I105924, I118773, I118920, I53845, I120479, I70680\n",
      "AD: I143685, I47186, I120436, I72873, I82700, I142001, I97022, I118924, I59174, I118880, I81373, I40828, I59677, I71451, I90925, I34195, I74600, I129629, I134210, I35014, I40378, I120476, I85469, I92420, I47177, I66787, I135775, I106467, I35039, I119731, I132359, I94432, I103276, I109893, I120441, I80152, I87547, I31540, I124421, I132795, I83521, I92205, I101541, I38887, I120575, I86377, I40352, I64862, I120469, I74659, I129655, I143178, I39200, I66768, I82651, I119729, I65374, I124097\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the CSV file with subject IDs and categories\n",
    "csv_file_path = 'E:/project2/ADNI1_Annual_2_Yr_3T_4_27_2023.csv'  # Replace with the actual path to your CSV file\n",
    "data_frame = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Create a dictionary to map subject IDs to categories\n",
    "subject_category_dict = dict(zip(data_frame['Image Data ID'], data_frame['Group']))\n",
    "\n",
    "# Iterate over the subject IDs and categorize them\n",
    "categorized_subjects = {}\n",
    "for subject_id in subject_category_dict:\n",
    "    category = subject_category_dict[subject_id]\n",
    "    if category in categorized_subjects:\n",
    "        categorized_subjects[category].append(subject_id)\n",
    "    else:\n",
    "        categorized_subjects[category] = [subject_id]\n",
    "\n",
    "# Print the categorized subject IDs\n",
    "for category, subjects in categorized_subjects.items():\n",
    "    print(f\"{category}: {', '.join(subjects)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_subjects"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# moving the files to respected folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\genericpath.py:42\u001b[0m, in \u001b[0;36misdir\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     st \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(s)\n\u001b[0;32m     43\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'E:/project2/ADNI_IP\\\\027_S_1387\\\\I129313'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m subject_id \u001b[39min\u001b[39;00m subjects:\n\u001b[0;32m     23\u001b[0m     subject_directory \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, subject_id)\n\u001b[1;32m---> 24\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49misdir(subject_directory):\n\u001b[0;32m     25\u001b[0m         \u001b[39m# Move each file in the subject directory to the category directory\u001b[39;00m\n\u001b[0;32m     26\u001b[0m         \u001b[39mfor\u001b[39;00m file_name \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(subject_directory):\n\u001b[0;32m     27\u001b[0m             source_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(subject_directory, file_name)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\genericpath.py:42\u001b[0m, in \u001b[0;36misdir\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m\"\"\"Return true if the pathname refers to an existing directory.\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     st \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(s)\n\u001b[0;32m     43\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Base directory of the NIfTI dataset\n",
    "base_directory = 'E:/project2/ADNI_IP'\n",
    "\n",
    "# Directory to store the categorized data\n",
    "output_directory = 'E:/project2/Categorized_Data'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Iterate over the subject IDs and categorize them\n",
    "for category, subjects in categorized_subjects.items():\n",
    "    # Create the category directory\n",
    "    category_directory = os.path.join(output_directory, category)\n",
    "    os.makedirs(category_directory, exist_ok=True)\n",
    "\n",
    "    # Traverse the base directory and move subject files to the category directory\n",
    "    for root, dirs, files in os.walk(base_directory):\n",
    "        for subject_id in subjects:\n",
    "            subject_directory = os.path.join(root, subject_id)\n",
    "            if os.path.isdir(subject_directory):\n",
    "                # Move each file in the subject directory to the category directory\n",
    "                for file_name in os.listdir(subject_directory):\n",
    "                    source_file = os.path.join(subject_directory, file_name)\n",
    "                    destination_file = os.path.join(category_directory, file_name)\n",
    "                    shutil.move(source_file, destination_file)\n",
    "                    \n",
    "                    # Print the file path to verify the movement\n",
    "                    print(f\"Moved: {destination_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(base_directory):\n",
    "    # Get the subject folder from the root directory\n",
    "    subject_folder = os.path.basename(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.walk(base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Directory containing the categorized data\n",
    "categorized_directory = 'E:/project2/Categorized_Data'\n",
    "\n",
    "# Preprocessing and normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for category in categorized_subjects.keys():\n",
    "    category_directory = os.path.join(categorized_directory, category)\n",
    "    preprocessed_images = []\n",
    "\n",
    "    for file_name in os.listdir(category_directory):\n",
    "        file_path = os.path.join(category_directory, file_name)\n",
    "        \n",
    "        # Load the NIfTI image\n",
    "        nifti_img = nib.load(file_path)\n",
    "        \n",
    "        # Extract the data array\n",
    "        data_array = nifti_img.get_fdata()\n",
    "\n",
    "        # Reshape the data array if necessary\n",
    "        reshaped_data = np.reshape(data_array, (-1, data_array.shape[-1]))\n",
    "\n",
    "        # Normalize the data using standardization\n",
    "        normalized_data = scaler.fit_transform(reshaped_data)\n",
    "\n",
    "        # Reshape the normalized data back to the original shape\n",
    "        normalized_data_array = np.reshape(normalized_data, data_array.shape)\n",
    "\n",
    "        preprocessed_images.append(normalized_data_array)\n",
    "        \n",
    "        # Perform additional preprocessing steps as needed\n",
    "        \n",
    "    # Continue with your desired operations on the preprocessed_images for the current category\n",
    "    # Example: Save the preprocessed images for the current category\n",
    "    save_directory = os.path.join(output_directory, category)\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "    \n",
    "    for i, preprocessed_image in enumerate(preprocessed_images):\n",
    "        save_file_path = os.path.join(save_directory, f\"preprocessed_image_{i}.nii\")\n",
    "        preprocessed_nifti = nib.Nifti1Image(preprocessed_image, nifti_img.affine, nifti_img.header)\n",
    "        nib.save(preprocessed_nifti, save_file_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['MCI', 'CN', 'AD'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorized_subjects.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = 'E:/project2/Categorized_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file with subject IDs and categories\n",
    "csv_file_path = 'E:/project2/ADNI1_Annual_2_Yr_3T_4_27_2023.csv'\n",
    "data_frame = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Create a dictionary to map subject IDs to categories\n",
    "subject_category_dict = dict(zip(data_frame['Image Data ID'], data_frame['Group']))\n",
    "\n",
    "# Create the categorized_subjects dictionary\n",
    "categorized_subjects = {}\n",
    "for subject_id in subject_category_dict:\n",
    "    category = subject_category_dict[subject_id]\n",
    "    if category in categorized_subjects:\n",
    "        categorized_subjects[category].append(subject_id)\n",
    "    else:\n",
    "        categorized_subjects[category] = [subject_id]\n",
    "\n",
    "print(categorized_subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prepare the feature matrix and target labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Iterate over the categorized subjects\n",
    "for category, subjects in categorized_subjects.items():\n",
    "    category_directory = os.path.join(output_directory, category)\n",
    "    \n",
    "    # Iterate over the preprocessed images for the current category\n",
    "    for i, subject_id in enumerate(subjects):\n",
    "        # Load the preprocessed image\n",
    "        file_name = f\"preprocessed_image_{i}.nii\"\n",
    "        file_path = os.path.join(category_directory, file_name)\n",
    "        \n",
    "        try:\n",
    "            nifti_img = nib.load(file_path)\n",
    "            data_array = nifti_img.get_fdata()\n",
    "            \n",
    "            # Add the flattened data array to the features list\n",
    "            features.append(data_array.flatten())\n",
    "            \n",
    "            # Add the corresponding label to the labels list\n",
    "            labels.append(category)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}. Skipping...\")\n",
    "            break\n",
    "\n",
    "    # Check if the loop was ended prematurely due to a file not found\n",
    "    else:\n",
    "        # Continue to the next category\n",
    "        continue\n",
    "\n",
    "    # If the loop was ended prematurely, break out of the outer loop\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_99.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_100.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_101.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_102.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_103.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_104.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_105.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_106.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_107.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_108.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_109.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_110.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_111.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_112.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_113.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_114.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_115.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_116.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_117.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_118.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_119.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_120.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_121.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_122.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_123.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_124.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_125.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_126.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_127.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_128.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_129.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_130.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_131.nii. Skipping...\n",
      "File not found: E:/project2/Categorized_Data\\MCI\\preprocessed_image_132.nii. Skipping...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prepare the feature matrix and target labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Iterate over the categorized subjects\n",
    "for category, subjects in categorized_subjects.items():\n",
    "    category_directory = os.path.join(output_directory, category)\n",
    "    \n",
    "    # Iterate over the preprocessed images for the current category\n",
    "    for i, subject_id in enumerate(subjects):\n",
    "        # Load the preprocessed image\n",
    "        file_name = f\"preprocessed_image_{i}.nii\"\n",
    "        file_path = os.path.join(category_directory, file_name)\n",
    "        \n",
    "        try:\n",
    "            nifti_img = nib.load(file_path)\n",
    "            data_array = nifti_img.get_fdata()\n",
    "            \n",
    "            # Add the flattened data array to the features list\n",
    "            features.append(data_array.flatten())\n",
    "            \n",
    "            # Add the corresponding label to the labels list\n",
    "            labels.append(category)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "# Convert the features and labels lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Random Forest classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "# Directory containing the preprocessed data\n",
    "preprocessed_directory = 'E:/project2/Categorized_Data'\n",
    "\n",
    "# Iterate over the categories\n",
    "for category in categorized_subjects.keys():\n",
    "    category_directory = os.path.join(preprocessed_directory, category)\n",
    "\n",
    "    # Iterate over the preprocessed files in the category directory\n",
    "    for file_name in os.listdir(category_directory):\n",
    "        file_path = os.path.join(category_directory, file_name)\n",
    "\n",
    "        # Load the preprocessed NIfTI image\n",
    "        preprocessed_nifti = nib.load(file_path)\n",
    "\n",
    "        # Access the preprocessed data array\n",
    "        preprocessed_data = preprocessed_nifti.get_fdata()\n",
    "\n",
    "        # Perform operations on the preprocessed data for each category\n",
    "        # Example: Pass the preprocessed data to your random forest model for prediction\n",
    "        # model.predict(preprocessed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
